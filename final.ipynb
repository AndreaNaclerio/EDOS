{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPjyNIXiBXkD5Pvg17ViUX4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NacliNaclo/EDOS/blob/main/final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# file_num = 000000\n",
        "# a =[0]*197\n",
        "# for i in range(0,count):\n",
        "#   image_path = '/content/drive/MyDrive/medical_robotics/v1/v1/frame_rgb/'+ str(file_num + i).zfill(6)+'.png'\n",
        "#   # Load the image without resizing or preprocessing\n",
        "#   image_1 = tf.io.read_file(image_path)\n",
        "#   image_1= tf.image.decode_image(image_1, channels=3)\n",
        "#   a[i] = image_1"
      ],
      "metadata": {
        "id": "SzhTmRBtiEWU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset = np.stack(a, axis=0)"
      ],
      "metadata": {
        "id": "3uz90HX0iGUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# np.save('/content/drive/MyDrive/medical_robotics/dataset.npy', dataset)"
      ],
      "metadata": {
        "id": "glNS4Vg7iIXK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DATASET"
      ],
      "metadata": {
        "id": "hokm0iwKh9Cx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bszDGUhie0Oz",
        "outputId": "3da76346-cef5-4c5d-ac4c-acc78c87f13d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "dBEmqdUAfLaP"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Q_m8LWXderZ2"
      },
      "outputs": [],
      "source": [
        "loaded_dataset = np.load('/content/drive/MyDrive/medical_robotics/dataset.npy')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_dataset.shape #so now we have created our dataset in the correct shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jYUv9VYTfcua",
        "outputId": "97bf90bc-2eb6-4ab5-b3ec-d142b0447134"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(197, 1024, 1280, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start_images = loaded_dataset[0:196,:,:,:] #the last image has no other correlated images in order to compute the homogenous trasnformation matrix"
      ],
      "metadata": {
        "id": "ZsQKPbs5fq86"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_images.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMcyNojogWct",
        "outputId": "88d2c908-33db-40bb-98cb-c8fd67cecd3a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(196, 1024, 1280, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_images = loaded_dataset[1:197,:,:,:] #the last index is exluded (so if we write 0:1 it extracts only 1 value, that in position 0)"
      ],
      "metadata": {
        "id": "6wgGHl4Cgbhz"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_images.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dkySdw5Xht3c",
        "outputId": "99b72b89-82c3-4cd3-9b29-21a1494f432d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(196, 1024, 1280, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# so now we have ur 2 dataset that will be input to our 2 network"
      ],
      "metadata": {
        "id": "_UPv9ywmhvhL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TARGET"
      ],
      "metadata": {
        "id": "vohq_56blY5v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json"
      ],
      "metadata": {
        "id": "PmFZyk2Lngbj"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tranformation_matrix_extrac(folder_path):\n",
        "  # looking for number of files in the folder\n",
        "  import os\n",
        "  count = 0\n",
        "  # Iterate directory\n",
        "  for path in os.listdir(folder_path):\n",
        "    # check if current path is a file\n",
        "    if os.path.isfile(os.path.join(folder_path, path)):\n",
        "        count += 1\n",
        "\n",
        "  file_num = 000000\n",
        "  tranf_matrices = [0]*(count-1)\n",
        "  for i in range(0,count-1): #the upper boundar is exclude\n",
        "    j = i + 1\n",
        "    source = folder_path + '/frame_data' + str(file_num + i).zfill(6) + '.json'\n",
        "    end = folder_path + '/frame_data' + str(file_num + j).zfill(6) + '.json'\n",
        "\n",
        "    f_source = open(source)\n",
        "    data_source = json.load(f_source)\n",
        "    T_0 = np.array(data_source['camera-pose'])\n",
        "\n",
        "    f_end = open(end)\n",
        "    data_end = json.load(f_end)\n",
        "    T_1 = np.array(data_end['camera-pose'])\n",
        "\n",
        "    tranf_matrices[i] = np.matmul(np.linalg.inv(T_0),T_1)\n",
        "\n",
        "  return tranf_matrices\n",
        "\n"
      ],
      "metadata": {
        "id": "na_q6htKldMf"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transf_matrices = tranformation_matrix_extrac('/content/drive/MyDrive/medical_robotics/v1/v1/frame_data')"
      ],
      "metadata": {
        "id": "UqoxeEUImS3r"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "targets = np.stack(transf_matrices, axis=0)"
      ],
      "metadata": {
        "id": "EcBxlnO9mlfo"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "targets.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WVofQK6ysbkv",
        "outputId": "6bb58188-7a78-4747-9f9e-3ad9998ff390"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(196, 4, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "targets[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4JnenScCmtzO",
        "outputId": "1e4bba62-5757-4074-d34e-7eeecaddf878"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 9.99996758e-01, -2.66848080e-03, -1.38534687e-04,\n",
              "        -1.76657959e-02],\n",
              "       [ 2.66837263e-03,  9.99996429e-01, -8.90276436e-04,\n",
              "        -1.13811995e-01],\n",
              "       [ 1.40861180e-04,  8.89828332e-04,  9.99999821e-01,\n",
              "         2.77779557e-01],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         1.00000000e+00]])"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "targets[0,0:3,3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4n_6KXNnyNt",
        "outputId": "2a5e1cbe-0a06-45ef-9185-3201e3e75e00"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.0176658 , -0.11381199,  0.27777956])"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## POSITION"
      ],
      "metadata": {
        "id": "IjUHqh0esBFZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "positions = [0]*196"
      ],
      "metadata": {
        "id": "8EW7ubReoCQg"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0,196):\n",
        "  positions[i] = targets[i,0:3,3]"
      ],
      "metadata": {
        "id": "vGfHFXwqoIPX"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "positions = np.stack(positions, axis=0)  #in order to move from an list to an array"
      ],
      "metadata": {
        "id": "E2IfCaRRo8F8"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "positions.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBt45obmpuaV",
        "outputId": "4ad628f2-5fa3-4e31-e3c0-91082cb485e6"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(196, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ORIENTATION"
      ],
      "metadata": {
        "id": "md8cSEJjsFJF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def matrix_to_rpy(R): # i think that this type of representation is not the correct one, since we have some ambiguity (the quaternians are better)\n",
        "    pitch = np.arcsin(-R[2, 0])\n",
        "    roll = np.arctan2(R[2, 1], R[2, 2])\n",
        "    yaw = np.arctan2(R[1, 0], R[0, 0])\n",
        "    return [roll, pitch, yaw]"
      ],
      "metadata": {
        "id": "ubGKhoBssJhf"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "angles = [0]*196\n",
        "for i in range(0,196):\n",
        "  angles[i] = matrix_to_rpy(targets[i,:,:])"
      ],
      "metadata": {
        "id": "k0Xrb8kptYM2"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "angles = np.stack(angles, axis=0)"
      ],
      "metadata": {
        "id": "pcFJK55EtmFb"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "angles.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjBkHheitrF0",
        "outputId": "f86bdb01-d9e9-4208-b645-7e826d3ab769"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(196, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MODEL"
      ],
      "metadata": {
        "id": "s0xJ-K_ah_Xq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(input_shape_1, input_shape_2):\n",
        "    tf.random.set_seed(seed)\n",
        "\n",
        "    # Build the neural network layer by layer (1st network)\n",
        "    input_layer_1 = tfkl.Input(shape=input_shape_1, name='Input')\n",
        "\n",
        "    conv1_1 = tfkl.Conv2D(\n",
        "        filters=32,\n",
        "        kernel_size=(3, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.HeUniform(seed)\n",
        "    )(input_layer_1)\n",
        "    pool1_1 = tfkl.MaxPooling2D(pool_size = (2, 2))(conv1_1)\n",
        "\n",
        "    conv2_1 = tfkl.Conv2D(\n",
        "        filters=64,\n",
        "        kernel_size=(3, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.HeUniform(seed)\n",
        "    )(pool1_1)\n",
        "    pool2_1 = tfkl.MaxPooling2D(pool_size = (2, 2))(conv2_1)\n",
        "\n",
        "    conv3_1 = tfkl.Conv2D(\n",
        "        filters=128,\n",
        "        kernel_size=(3, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.HeUniform(seed)\n",
        "    )(pool2_1)\n",
        "    pool3_1 = tfkl.MaxPooling2D(pool_size = (2, 2))(conv3_1)\n",
        "\n",
        "    flattening_layer_1 = tfkl.Flatten(name='Flatten')(pool3_1)\n",
        "\n",
        "#############################################################################\n",
        "\n",
        "    #2nd network\n",
        "    input_layer_2 = tfkl.Input(shape=input_shape_2, name='Input')\n",
        "\n",
        "    conv1_2 = tfkl.Conv2D(\n",
        "        filters=32,\n",
        "        kernel_size=(3, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.HeUniform(seed)\n",
        "    )(input_layer_2)\n",
        "    pool1_2 = tfkl.MaxPooling2D(pool_size = (2, 2))(conv1_2)\n",
        "\n",
        "    conv2_2 = tfkl.Conv2D(\n",
        "        filters=64,\n",
        "        kernel_size=(3, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.HeUniform(seed)\n",
        "    )(pool1_2)\n",
        "    pool2_2 = tfkl.MaxPooling2D(pool_size = (2, 2))(conv2_2)\n",
        "\n",
        "    conv3_2 = tfkl.Conv2D(\n",
        "        filters=128,\n",
        "        kernel_size=(3, 3),\n",
        "        strides = (1, 1),\n",
        "        padding = 'same',\n",
        "        activation = 'relu',\n",
        "        kernel_initializer = tfk.initializers.HeUniform(seed)\n",
        "    )(pool2_2)\n",
        "    pool3_2 = tfkl.MaxPooling2D(pool_size = (2, 2))(conv3_2)\n",
        "\n",
        "    flattening_layer_2 = tfkl.Flatten(name='Flatten')(pool3_2)\n",
        "\n",
        "\n",
        "############################################################################\n",
        "\n",
        "    # now we need to merge the due flattering layer from the 2 network and at\n",
        "    # then input it inside the classification model\n",
        "\n",
        "    merged = Concatenate()([flattening_layer_1,flattening_layer_2])\n",
        "\n",
        "\n",
        "###########################################################################\n",
        "\n",
        "\n",
        "    # classifation layer\n",
        "\n",
        "    classifier_layer = tfkl.Dense(\n",
        "        units=128,\n",
        "        name='Classifier',\n",
        "        activation='relu',\n",
        "        kernel_initializer = tfk.initializers.HeUniform(seed)\n",
        "    )(merged)\n",
        "\n",
        "    classifier_layer = tfkl.Dropout(0.5, seed=seed)(classifier_layer)\n",
        "    output_layer = tfkl.Dense(\n",
        "        units=6,\n",
        "        activation='softmax',\n",
        "        kernel_initializer = tfk.initializers.GlorotUniform(seed),\n",
        "        name='Output'\n",
        "    )(classifier_layer)\n",
        "\n",
        "    # Connect input and output through the Model class\n",
        "    model = tfk.Model(inputs=input_layer, outputs=output_layer, name='model')\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(), metrics='accuracy')\n",
        "\n",
        "    # Return the model\n",
        "    return model"
      ],
      "metadata": {
        "id": "4a83VOV6iA56"
      },
      "execution_count": 92,
      "outputs": []
    }
  ]
}